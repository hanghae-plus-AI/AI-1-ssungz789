{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\ssungz/.cache\\torch\\hub\\huggingface_pytorch-transformers_main\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00006025089e4855bc39d61762033bc8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0e5962de6264170b2a57674ba6d02c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/816k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56e53b3c41de4b849e2f6806af6ce2c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/458k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a239726c0cc48ea92f1dc56ac099c71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.27M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ssungz\\AppData\\Roaming\\Python\\Python312\\site-packages\\transformers\\tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from datasets import load_dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "tokenizer = torch.hub.load('huggingface/pytorch-transformers', 'tokenizer', 'openai-gpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "ds = load_dataset(\"fancyzhx/ag_news\")\n",
    "tokenizer.pad_token = tokenizer.unk_token\n",
    "\n",
    "def collate_fn(batch):\n",
    "  max_len = 400\n",
    "  texts, labels = [], []\n",
    "  for row in batch:\n",
    "    labels.append(row['label'])\n",
    "    texts.append(row['text'])\n",
    "\n",
    "  texts = torch.LongTensor(tokenizer(texts, padding='max_length', truncation=True, max_length=max_len).input_ids)\n",
    "  labels = torch.LongTensor(labels)\n",
    "\n",
    "  return texts, labels\n",
    "\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    ds['train'], batch_size=64, shuffle=True, collate_fn=collate_fn\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    ds['test'], batch_size=64, shuffle=False, collate_fn=collate_fn\n",
    ")\n",
    "\n",
    "unique_labels = set()\n",
    "for split in ['train']:\n",
    "    for item in ds[split]:\n",
    "        unique_labels.add(item['label'])\n",
    "\n",
    "num_classes = len(unique_labels)\n",
    "print(num_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['text', 'label'],\n",
      "    num_rows: 120000\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(ds['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\ssungz/.cache\\torch\\hub\\huggingface_pytorch-transformers_main\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OpenAIGPTModel(\n",
       "  (tokens_embed): Embedding(40478, 768)\n",
       "  (positions_embed): Embedding(512, 768)\n",
       "  (drop): Dropout(p=0.1, inplace=False)\n",
       "  (h): ModuleList(\n",
       "    (0-11): 12 x Block(\n",
       "      (attn): Attention(\n",
       "        (c_attn): Conv1D(nf=2304, nx=768)\n",
       "        (c_proj): Conv1D(nf=768, nx=768)\n",
       "        (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "        (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp): MLP(\n",
       "        (c_fc): Conv1D(nf=3072, nx=768)\n",
       "        (c_proj): Conv1D(nf=768, nx=3072)\n",
       "        (act): NewGELUActivation()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = torch.hub.load('huggingface/pytorch-transformers', 'model', 'openai-gpt')\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\ssungz/.cache\\torch\\hub\\huggingface_pytorch-transformers_main\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TextClassifier(\n",
       "  (encoder): OpenAIGPTModel(\n",
       "    (tokens_embed): Embedding(40478, 768)\n",
       "    (positions_embed): Embedding(512, 768)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-11): 12 x Block(\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D(nf=2304, nx=768)\n",
       "          (c_proj): Conv1D(nf=768, nx=768)\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D(nf=3072, nx=768)\n",
       "          (c_proj): Conv1D(nf=768, nx=3072)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): Linear(in_features=768, out_features=4, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch import nn\n",
    "\n",
    "\n",
    "class TextClassifier(nn.Module):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "\n",
    "    self.encoder = torch.hub.load('huggingface/pytorch-transformers', 'model', 'openai-gpt')\n",
    "    self.classifier = nn.Linear(768, num_classes)\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = self.encoder(x)['last_hidden_state']\n",
    "    x = self.classifier(x[:, -1])\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "model = TextClassifier()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 질문사항 (평가 시 이 부분에 대해 코멘트가 가능하다면 부탁드립니다.) ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 아래 코드로 학습 시 accuracy 값이 현저 히 낮은데 \n",
    "##\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class TextClassifier(nn.Module):\n",
    "  def __init__(self, num_classes, hidden_size=256, dropout_rate=0.5):\n",
    "    super().__init__()\n",
    "\n",
    "    self.encoder = torch.hub.load('huggingface/pytorch-transformers', 'model', 'openai-gpt')\n",
    "    self.dropout = nn.Dropout(dropout_rate)\n",
    "    self.bn = nn.BatchNorm1d(hidden_size)\n",
    "    self.intermediate = nn.Linear(768, hidden_size)\n",
    "    self.classifier = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = self.encoder(x)['last_hidden_state']\n",
    "    x = x[:, -1]\n",
    "    x = self.dropout(x)\n",
    "    x = self.intermediate(x)\n",
    "    x = self.bn(x)\n",
    "    x = F.relu(x)\n",
    "    x = self.classifier(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "model = TextClassifier(num_classes)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.encoder.parameters():\n",
    "  param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   0 | Train Loss: 2356.035525918007\n",
      "Epoch   1 | Train Loss: 2039.858066380024\n",
      "Epoch   2 | Train Loss: 1880.4663382172585\n",
      "Epoch   3 | Train Loss: 1784.542182803154\n",
      "Epoch   4 | Train Loss: 1723.501572072506\n",
      "Epoch   5 | Train Loss: 1674.478139281273\n",
      "Epoch   6 | Train Loss: 1648.0704543590546\n",
      "Epoch   7 | Train Loss: 1621.1899408102036\n",
      "Epoch   8 | Train Loss: 1602.7535386681557\n",
      "Epoch   9 | Train Loss: 1584.0639610290527\n"
     ]
    }
   ],
   "source": [
    "from torch.optim import Adam\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "lr = 0.0001\n",
    "model = model.to('cuda')\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = Adam(model.parameters(), lr=lr)\n",
    "n_epochs = 10\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "  total_loss = 0.\n",
    "  model.train()\n",
    "  for data in train_loader:\n",
    "    model.zero_grad()\n",
    "    inputs, labels = data\n",
    "    inputs, labels = inputs.to('cuda'), labels.to('cuda')\n",
    "\n",
    "    preds = model(inputs)\n",
    "    loss = loss_fn(preds, labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    total_loss += loss.item()\n",
    "\n",
    "  print(f\"Epoch {epoch:3d} | Train Loss: {total_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========> Train acc: 0.737 | Test acc: 0.731\n"
     ]
    }
   ],
   "source": [
    "def accuracy(model, dataloader):\n",
    "  cnt = 0\n",
    "  acc = 0\n",
    "\n",
    "  for data in dataloader:\n",
    "    inputs, labels = data\n",
    "    inputs, labels = inputs.to('cuda'), labels.to('cuda')\n",
    "\n",
    "    preds = model(inputs)\n",
    "    preds = torch.argmax(preds, dim=-1)\n",
    "    # preds = (preds > 0).long()[..., 0]\n",
    "\n",
    "    cnt += labels.shape[0]\n",
    "    acc += (labels == preds).sum().item()\n",
    "\n",
    "  return acc / cnt\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "  model.eval()\n",
    "  train_acc = accuracy(model, train_loader)\n",
    "  test_acc = accuracy(model, test_loader)\n",
    "  print(f\"=========> Train acc: {train_acc:.3f} | Test acc: {test_acc:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
