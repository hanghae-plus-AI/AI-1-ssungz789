import streamlit as st
from langchain_community.document_loaders import WebBaseLoader
from langchain.text_splitter import CharacterTextSplitter
from langchain_community.embeddings import OpenAIEmbeddings
from langchain_community.vectorstores import Chroma
from langchain.chains import ConversationalRetrievalChain
from langchain_openai import ChatOpenAI
import os

# OpenAI API í‚¤ ì„¤ì •
os.environ["OPENAI_API_KEY"] = st.secrets["OPENAI_API_KEY"]

# ì œëª©
st.title('ìŠ¤íŒŒë¥´íƒ€ AI ì±—ë´‡ ğŸ¤–')

# ì´ˆê¸° ì„¤ì •
@st.cache_resource
def initialize_chain():
    # ì›¹í˜ì´ì§€ ë¡œë“œ
    loader = WebBaseLoader("https://spartacodingclub.kr/blog/all-in-challenge_winner")
    documents = loader.load()

    # í…ìŠ¤íŠ¸ ë¶„í• 
    text_splitter = CharacterTextSplitter(
        chunk_size=1000,
        chunk_overlap=200
    )
    texts = text_splitter.split_documents(documents)

    # ì„ë² ë”© ë° ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ ìƒì„±
    embeddings = OpenAIEmbeddings()
    vectorstore = Chroma.from_documents(
        documents=texts,
        embedding=embeddings,
        persist_directory="./chroma_db"
    )

    # ChatGPT ëª¨ë¸ ì„¤ì •
    llm = ChatOpenAI(model_name="gpt-4", temperature=0)

    # Conversational Retrieval Chain ìƒì„±
    chain = ConversationalRetrievalChain.from_llm(
        llm,
        vectorstore.as_retriever(),
        return_source_documents=True
    )

    return chain

# ì²´ì¸ ì´ˆê¸°í™”
chain = initialize_chain()

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if "messages" not in st.session_state:
    st.session_state.messages = []

if "chat_history" not in st.session_state:
    st.session_state.chat_history = []

# ë©”ì‹œì§€ í‘œì‹œ
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬
if prompt := st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”"):
    st.session_state.messages.append({"role": "user", "content": prompt})

    with st.chat_message("user"):
        st.markdown(prompt)

    with st.chat_message("assistant"):
        response = chain(
            {"question": prompt, "chat_history": st.session_state.chat_history}
        )

        st.markdown(response["answer"])

        # ì±„íŒ… ê¸°ë¡ ì—…ë°ì´íŠ¸
        st.session_state.messages.append({"role": "assistant", "content": response["answer"]})
        st.session_state.chat_history.extend([(prompt, response["answer"])])
